CSFM: COMMUNITY-BASED STRUCTURE FROM MOTION
============================================

在本文提出了一种基于 **Community** （以下翻译为社区）的自适应 SfM（CSfM）方法，该方法同时考虑了鲁棒性和效率，解决了三个凸 L1 优化问题。

1. 对极几何图形被划分为单独的社区 。

2. 并行解决每个社区的重建问题。

3. 通过一种新颖的全局相似性平均方法合并重建结果。

全局 SfM 方法同时从对极几何图 (EG) 计算相机位姿，其中顶点对应于图像和边缘链接匹配的图像对，并且仅执行BA调整 一次。
然而，那些基于基本矩阵的方法对极线几何异常值更敏感，它们只能校准平行刚性图中的图像。 造成的结果是，因为 EG 可能不够密集和准确，许多有用的图像可能会被丢弃。

传统的 SfM 方法通常将所有图像视为一个单独的社区，但对于大规模场景重建，特别是对于那些从互联网上搜索到的无序图像，图像分布通常具有社区特征：
一些地方得到图像更密集，而其他地方的图像更稀疏。在这种情况下，同时重建所有图像并不是一个合理的选择。

在本文中，提出了一种自动检测图像数据是否具有社区特征的方法，如果具有，则首先将图像划分为独立的社区，然后对每个社区并行进行重建，然后进行合并步骤将所有重建结果对齐到一个统一的全局框架中。

.. note::

   :贡献:

      1. 提出了一种自动社区检测方法来确定图像数据集是否应该划分为社区。

      2. 提出了一种社区图构建方法，将对极几何图划分为内部连接较密、外部连接较稀疏的组。

      3. 提出了一种新的全局相似性平均方法，将每个社区中所有单独的重建结果合并到一个统一的全局框架中。

.. figure:: 1.jpg
   :figclass: align-center

COMMUNITY DETECTION
-------------------

社区检测已广泛用于复杂网络分析，目的是将图划分为内部连接较密集和外部连接较稀疏的子图。

.. attention::

   给定对极几何图（EG），其顶点对应图像，边缘链接匹配的图像对，目标是检测图像数据是否具有社区特征以及存在多少社区。

设 :math:`A_{ij}` 是 EG 的相邻矩阵的一个元素。 如果相机 :math:`i` 和相机 :math:`j` 相连，则 :math:`A_{ij} = 1` ，否则 :math:`A_{ij} = 0` 。

令  :math:`d_i = \sum\limits_j A_{ij}`  为 EG 中顶点 :math:`i` 的度数，表示连接到第 :math:`i` 个相机的相机数量， :math:`m = \frac{1}{2} \sum\limits_{ij}A_{ij}` 是 EG 中的边数。

那么，如果对极边的存在是随机的，则连接相机 :math:`i` 和相机 :math:`j` 的边的存在概率为：

.. math::

   \frac{d_i d_j}{2m}

为了测量随机图和 EG 之间的社区内连接分数的差异，使用《Finding com- munity structure in very large networks》中提出的模块化指标 Q。

假设摄像机 :math:`i` 属于社区  :math:`U_p` ，摄像机 :math:`j` 属于社区 :math:`U_q` ，则 :math:`Q` 定义为：

.. math::

   Q = \frac{1}{2m} \sum\limits_{ij}(A_{ij} - \frac{d_i d_j}{2m}) \delta (U_p, U_q)

如果  :math:`U_p = U_q` ，则  :math:`\delta (U_p, U_q) = 1` ，否则为 0。

为了划分 EG，假设每个节点首先属于一个单独的社区，然后当合并导致 Q 的最大增加时，单独的社区被迭代地加入。

在树状图的生成过程中，模块性有一个单一的峰值  :math:`Q_{max}` ，这表明最重要的社区结构。在实践中发现  :math:`Q_{max} > 0.3` 表明 EG 具有显着的社区结构。
因此，当 Q 的峰值大于 0.3 时，取分区结果。 如果  :math:`Q_{max} < 0.3` ，则应将所有图像视为单个社区。

然而，对于大规模场景重建问题，一次性分区通常是不够的，因为一些当前分区仍然具有社区特征。 因此需要迭代地划分 EG，直到每个划分结果都可以被视为一个社区。
当迭代完成时，得到一个社区图，它的顶点对应社区，边连接社区。

.. attention::

   请注意，当一对社区之间存在一些极线边缘时，它们是相互关联的。

.. figure:: 2.jpg
   :figclass: align-center

考虑到场景重建的鲁棒性，每个社区都应该为后续的合并步骤重建足够的 3D 点，因此本文为每个社区设置了最小数量的图像 N

.. note::

   在本文工作中，N 设置为 20

迭代收敛后，将那些图像数量小于 N 的小数据集合并到它们最近的连接社区中。两个社区之间的紧密程度被定义为跨越它们的对极几何边的数量。

GLOBAL SIMILARITY AVERAGING
----------------------------

社区检测后，每个社区的图像连接变得更加密集，因此可以使用许多 SfM 方法进行重建。社区通常构建一个连通图，因此本文提出了一种全局相似性平均方法来鲁棒地对齐这些单独的重建结果。

Global Scale Averaging
~~~~~~~~~~~~~~~~~~~~~~~~

设 :math:`s_i` 为第 i 个社区的尺度， :math:`s_{ij}` 为社区 :math:`U_i` 和 :math:`U_j` 之间 3D 相似性变换中的比例因子。

给定 :math:`\frac{s_i}{s_j} = s_{ij}` ，通过取双方的对数函数：

.. math::

   log(s_i) - log(s_j) = log(s_{ij})

通过从所有连接的社区对堆叠上述方程，得到一个线性方程组：

.. math::

   A_s * x_s = b_s

其中  :math:`x_s` 和 :math:`b_s` 是分别连接  :math:`log(s_i)`  和  :math:`log(s_{ij})`  的向量， :math:`A_s`  是一个稀疏矩阵，其中只有 1 和 -1。

由于尺度估计达到全局尺度，为了消除规范歧义，将第一个社区 :math:`s_1` 的尺度设置为单位： :math:`log(s_1) = 0` 。

然后，方程系统通过以下 L1 优化：

.. math::

   ||A_s ∗ x_s − b_s||_{L1}

.. note::

   请注意，此 L1 优化是凸的。

Global Rotation Averaging
~~~~~~~~~~~~~~~~~~~~~~~~~~

设 :math:`R_i` 为第 :math:`i` 个社区的旋转变换， :math:`R_{ij}` 为社区 :math:`U_i` 和 :math:`U_j` 之间3D相似度变换中的相对旋转变换。

给定 :math:`R_{ij} = R_j * R_i^T` 通过对两边取对数，得到它们对应的角度轴向量之间的等式：

.. math::

   w_{ij} = w_j - w_i

其中 :math:`w_{ij}` 是 :math:`R_{ij}` 对应的角轴矢量， :math:`w_i` 、 :math:`w_j` 分别是 :math:`R_i` 和 :math:`R_j` 对应的角轴矢量。

通过从所有连接的社区对中叠加上述方程，得到了一个线性方程组，使用L1RA方法求解旋转平均。

然后对于第 :math:`i` 个社区，给定其尺度  :math:`s_i`  和旋转变换 :math:`R_i` ，将其第 k 个场景点 :math:`X_{ik}` 变换为  :math:`s_i ∗ R_i ∗ X_{ik}` 。 在此转换之后，重新计算一对连接社区之间的位移  :math:`T_{ij}` 。

Global Translation Averaging
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

设 :math:`T_i` 为第 :math:`i` 个社区的平移变换， :math:`T_{ij}` 为社区 :math:`U_i` 和 :math:`U_j` 之间 3D 相似变换中的相对平移变换。

类似地，通过从所有连接的社区对中叠加方程 :math:`T_{ij} = T_j - T_i` ，就有了一个线性方程组，然后，该方程组通过以下 L1 优化求解：

.. math::

   ||A_t ∗ x_t − b_t||_{L1}

其中  :math:`x_t` 和 :math:`b_t` 是通过分别连接 :math:`T_i` 和 :math:`T_{ij}` 的向量，并且 :math:`A_t` 是一个稀疏矩阵，其中非零值只有 1 和 -1。

由于位移估计取决于全局位移变换，为了消除规范歧义，将第一个社区的位移设置为零， :math:`T_1 = 0` 。

Reconstructions Merging
------------------------

给定每个社区的尺度、旋转、平移变换，所有社区的重建结果（3D 场景点和相机位姿）被合并到一个单一的全局框架中。

对于第 :math:`i` 个社区，其第 k 个 3D 场景点 :math:`X_{ik}^o` 转换为：

.. math::

   X_{ik}^g = X_{ik}^o + T_i

对于第 :math:`i` 个社区中的第 :math:`j` 个摄像机，其摄像机旋转 :math:`R_{ij}^o` 和摄像机中心 :math:`C_{ij}` 被转换为：

.. math::

   \begin{eqnarray}
      R_{ij}^g &=& R_{ij}^o * R_i^T\\
      C_{ij}^g &=& s_i * R_i * C_{ij}^o + T_i
   \end{eqnarray}


其中 :math:`X_{ij}^g,R_{ij}^g,C_{ij}^g` 分别表示最终统一全局框架中的变换 3D 场景点、相机旋转和相机中心。 合并后，执行最终的BA调整以进一步细化所有相机位姿和场景点。